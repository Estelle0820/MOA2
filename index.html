<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>MOA2 Experiment</title>

  <!-- jsPsych CSS -->
  <link rel="stylesheet" href="https://unpkg.com/jspsych@7.3.4/css/jspsych.css" />

 <style>
    /* Layout & base */
    .jspsych-content-wrapper { display: flex; justify-content: center; }
    .jspsych-content { max-width: 960px !important; margin: 40px auto !important; }
    body { font-family: system-ui, sans-serif; background: #fafafa; line-height: 1.6;}

    /* Center utility (apply only where desired) */
    .center { text-align: center; }
    h2.center, h3.center { text-align: center; }

    /* Lists default to left-aligned */
    ol, ul { text-align: left; margin-left: 1.5em; }

    /* Media & grid */
    video { display: block; margin: 0 auto; border-radius: 10px; background: #000; }
    .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; align-items: start; }
    .cell { text-align: center; }
    .tag { font-weight: 700; margin: 6px 0 8px; }

    /* Question stem & options */
    .stem  { display: block; margin: 8px auto 16px; max-width: 900px; width: 100%; height: 260px; object-fit: contain; }
    .optimg{ width: 100%; max-width: 360px; height: 220px; object-fit: contain; display: block; margin: 8px auto; background: #fff; }
    .opttext{ margin: 10px 8px; }

    /* Slider labels: 0–4 */
    .jspsych-slider-container .jspsych-slider-labels {
      display: flex !important;
      justify-content: space-between !important;
      gap: 0 !important;
      margin-top: 10px !important;
      font-size: 14px !important;
      line-height: 1.2 !important;
      color: #111 !important;
      white-space: nowrap !important;
    }
    .jspsych-slider-container .jspsych-slider-label {
      text-align: center !important;
      flex: 0 0 auto !important;
    }

    /* Hide seek bar + time displays */
    video::-webkit-media-controls-timeline,
    video::-webkit-media-controls-current-time-display,
    video::-webkit-media-controls-time-remaining-display { display: none !important; }
    video::-moz-media-controls-seekbar { display: none !important; }
  </style>
</head>
<body></body>

<!-- CSV parser -->
<script src="https://unpkg.com/papaparse@5.4.1/papaparse.min.js"></script>

<script type="module">
  /* ==============================
     Boot & imports
  ============================== */
  // Show JS errors on the page (handy in prod testing)
  window.onerror = (m, s, l, c, e) => {
    document.body.innerHTML = "<pre style='white-space:pre-wrap'>" + m + "\n" + (e && e.stack || "") + "</pre>";
  };

  // ESM imports
  import { initJsPsych } from "https://esm.sh/jspsych";
  import jsPsychHtmlSliderResponse from "https://esm.sh/@jspsych/plugin-html-slider-response";
  import jsPsychHtmlButtonResponse from "https://esm.sh/@jspsych/plugin-html-button-response";
  import jsPsychSurveyText from "https://esm.sh/@jspsych/plugin-survey-text";

  /* ==============================
     Data Store
  ============================== */
  const SHEET_URL = "https://script.google.com/macros/s/AKfycbz-5GhXQzK2N9ld_orabc1mwXOdhS_HSSOt00eMoNfWIqPtfK3X_pX-pkTxDS80PGXjCA/exec";

  const jsPsych = initJsPsych({
    on_finish: async () => {
      const payload = {
        timestamp: new Date().toISOString(),
        participant: getParam("pid") || "",
        data: jsPsych.data.get().values()
      };
      try {
        await fetch(SHEET_URL, {
          method: "POST",
          mode: "no-cors",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(payload),
          keepalive: true
        });
        alert("Thanks! Your data was uploaded to Google Sheets.");
      } catch (e) {
        console.error(e);
        jsPsych.data.get().localSave("csv", "single_trial_demo.csv");
        alert("Upload failed — CSV downloaded locally instead.");
      }
    }
  });

  /* ==============================
     Helpers
  ============================== */
  function getParam(name) {
    const m = new URLSearchParams(location.search).get(name);
    return m ? decodeURIComponent(m) : "";
  }

  // Build filename; maps "0s" -> "sync" if that's how files are named.
  function filename(scene, version, dir, moa) {
    const v = String(version).startsWith("v") ? String(version) : `v${version}`;
    const moaTag = (moa === "0s") ? "sync" : moa;
    return `videos/${scene}_${v}_${dir}_${moaTag}.mp4`;
  }

  // Parse id like "penguin_v2_q14" -> { scene:"penguin", version:"v2", q:"14" }
  function parseId(id) {
    const m = (id || "").trim().match(/^([a-z0-9_-]+)_v([123])_q(\d+)$/i);
    if (!m) return { scene: "", version: "", q: "" };
    const scene = m[1].toLowerCase();
    const version = `v${m[2]}`;
    const q = m[3];
    return { scene, version, q };
  }

  async function loadCSV(path = "logic.csv") {
    return new Promise((resolve, reject) => {
      if (typeof Papa === "undefined") {
        reject(new Error("Papa Parse not loaded. Make sure the <script> tag is included before this module."));
        return;
      }
      Papa.parse(`${path}?cb=${Date.now()}`, {
        download: true,
        header: true,
        skipEmptyLines: true,
        complete: (res) => {
          try {
            const rows = res.data.map(r => {
              // normalize keys and values
              const obj = {};
              for (const k in r) obj[k.trim()] = (r[k] ?? "").toString().trim();

              // enrich with scene/version/q from id (if provided)
              const parsed = parseId(obj.id || "");
              if (!obj.scene)   obj.scene   = parsed.scene;
              if (!obj.version) obj.version = parsed.version;
              if (!obj.q)       obj.q       = parsed.q;

              // canonicalize
              obj.scene = (obj.scene || "").toLowerCase();
              if (obj.version && !String(obj.version).startsWith("v")) {
                obj.version = `v${obj.version}`;
              }
              return obj;
            });
            resolve(rows);
          } catch (err) {
            reject(err);
          }
        },
        error: reject
      });
    });
  }

  function questionsFor(rows, scene, v) {
    const sceneKey = (scene || "").toLowerCase();
    const versionKey = String(v).startsWith("v") ? String(v) : `v${v}`;
    return rows.filter(r => (r.scene === sceneKey) && (r.version === versionKey));
  }

  function getStem(q, side) {
    const keys = [ `stemImage_${side}`, `${side}_stem`, `stem_${side}` ];
    for (const k of keys) {
      const val = q[k];
      if (val && typeof val === "string" && val.trim().length) return val.trim();
    }
    return "";
  }

  // Lock playback rate (resilient to user changes)
  function lockRate(video, rate) {
    const apply = () => { video.defaultPlaybackRate = rate; video.playbackRate = rate; };
    const end = performance.now() + 2000;
    (function tick(){ apply(); if (performance.now() < end) requestAnimationFrame(tick); })();
    const reapply = () => apply();
    ["play","ratechange","seeking","loadeddata","ended"].forEach(ev => {
      video.addEventListener(ev, reapply);
    });
  }

  /* ==============================
     Trial builders
  ============================== */
  function videoTrial(stimulus, meta) {
    return {
      type: jsPsychHtmlButtonResponse,
      stimulus: `
        <div class="wrap center">
          <p>Click "Play" to watch the clip. "Continue" will appear after it ends.</p>
          <video id="trial-video" width="900" controls playsinline preload="metadata">
            <source src="${stimulus}" type="video/mp4">
          </video>
        </div>`,
      choices: ["Continue"],
      data: { phase: "video", stimulus, ...meta },
      on_load: () => {
        const btn = document.querySelector(".jspsych-btn");
        const v = document.getElementById("trial-video");
        if (btn) btn.style.display = "none";
        const showContinue = () => { if (btn) btn.style.display = ""; };

        const firstPlay = () => {
          v.removeAttribute("controls");
          v.addEventListener("pause", () => { if (!v.ended) v.play().catch(()=>{}); });
          v.removeEventListener("play", firstPlay);
        };
        v.addEventListener("play", firstPlay);

        lockRate(v, 1.0);
        v.addEventListener("ended", () => { showContinue(); }, { once: true });
        v.addEventListener("contextmenu", e => e.preventDefault());
      }
    };
  }

  function questionTrial(q, side, meta) {
    const stem = getStem(q, side);

    // Build option objects with original indices
    const raw = ["a","b","c","d"]
      .map((k,i) => ({ val: (q[`${side}_${k}`] || "").trim(), origIndex: i }))
      .filter(o => o.val.length > 0);

    // The correct index as authored (0..3)
    const authoredCorrect = Number(q[`correct_${side}_index`]) || 0;

    // Shuffle the options
    const opts = jsPsych.randomization.shuffle(raw);

    // Where did the original correct option end up?
    const correctIndex = opts.findIndex(o => o.origIndex === authoredCorrect);

    const label = i => String.fromCharCode(65 + i); // A,B,C,D

    const optionsHTML = opts.map((o,i) => {
      const isImage = /\.(png|jpe?g|gif|webp)$/i.test(o.val);
      const content = isImage
        ? `<img class="optimg" src="${o.val}" alt="opt ${label(i)}">`
        : `<div class="opttext">${o.val}</div>`;
      return `
        <div class="cell">
          <div><strong>${label(i)}</strong></div>
          ${content}
          <div style="margin-top:8px">
            <button class="jspsych-btn" data-choice="${i}">Choose ${label(i)}</button>
          </div>
        </div>`;
    }).join("");

    const stemHTML = stem
      ? (/\.(png|jpe?g|gif|webp)$/i.test(stem) ? `<img class="stem" src="${stem}">`
                                               : `<div class="stem opttext">${stem}</div>`)
      : "";

    const prompt = (q.prompt || "")
      .replace(/^"(.*)"$/,'$1')
      .normalize("NFKC")
      .replace(/[\u2018\u2019]/g, "'")
      .replace(/[\u201C\u201D]/g, '"');

    return {
      type: jsPsychHtmlButtonResponse,
      stimulus: `
        <div class="wrap">
          <div class="center" style="margin-bottom:8px">
            <p><strong>${prompt}</strong></p>
          </div>
          ${stemHTML}
          <div class="grid">${optionsHTML}</div>
        </div>`,
      choices: [],
      on_load: () => {
        document.querySelectorAll("button[data-choice]").forEach(btn => {
          btn.onclick = () => {
            const choice = Number(btn.dataset.choice);
            jsPsych.finishTrial({
              phase: "question",
              qid: q.id || "",
              scene: q.scene || "",
              version: q.version || "",
              side,
              option_order: opts.map(o => o.origIndex).join(","), // e.g., "2,0,1,3"
              choice_index: choice,
              correct_index: correctIndex,
              is_correct: choice === correctIndex,
              ...meta
            });
          };
        });
      }
    };
  }

  function prefSlider(t) {
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>How much did you like the clip you just watched?</strong></p></div>',
      min: 0, max: 4, step: 1, slider_start: 2,
      slider_width: 700,
      labels: ['0 (Not at all)','1','2 (Neutral)','3','4 (Very much)'],
      require_movement: true,
      data: { phase: "preference", ...t }
    };
  }

  function simultaneitySlider(t) {
    return {
      type: jsPsychHtmlSliderResponse,
      stimulus: '<div class="center"><p><strong>To what extent did the visual and auditory motion begin at the same time?</strong></p></div>',
      min: 0, max: 4, step: 1, slider_start: 2,
      slider_width: 700,
      labels: ['0 (Very far apart)','1','2 (Somewhat apart)','3','4 (Exactly the same time)'],
      require_movement: true,
      data: { phase: "simultaneity_slider", ...t }
    };
  }

  function screenTrial(html, btn = "Continue") {
    return {
      type: jsPsychHtmlButtonResponse,
      stimulus: `<div class="wrap">${html}</div>`,
      choices: [btn]
    };
  }

  function oneTextQuestion({ name, prompt, placeholder = "", required = true, button = "Continue" }) {
    return {
      type: jsPsychSurveyText,
      preamble: `<div class="center"><h2>Final Questions</h2></div>`,
      questions: [
        { prompt: `<p style="font-weight:600;margin:0 0 8px">${prompt}</p>`, name, required, placeholder }
      ],
      button_label: button,
      on_load: () => {
        const style = document.createElement("style");
        style.textContent = `
          .jspsych-survey-text .jspsych-survey-text-preamble { text-align:center; }
          .jspsych-survey-text-question { max-width:720px; margin:0 auto 18px; text-align:left; }
          .jspsych-survey-text-question input {
            width:100%; padding:10px; border-radius:8px; border:1px solid #ddd; font-size:16px;
          }
          .jspsych-btn { padding:10px 18px; border-radius:8px; }
        `;
        document.head.appendChild(style);
      }
    };
  }

  /* ==============================
     Design 
  ============================== */
  const SCENES   = ["dog","horse","penguin","plane","car","roomba"];
  const VERSIONS = [1,2,3];
  // If your files are literally "..._sync.mp4", keep MOAS = ["0s","1s","3s"] and rely on filename() mapping.
  const MOAS     = ["0s","1s","3s"];

  (async () => {
    // URL overrides for practice (optional)
    const PRACTICE_VIDEO = getParam("pvid") || "videos/practice_v1.mp4";
    const PRACTICE_SIDE  = (getParam("pside") || "left").toLowerCase() === "right" ? "right" : "left";

    // Load CSV once
    const rows = await loadCSV("logic.csv");

    /* ---------- Practice ---------- */
    const practiceQs = questionsFor(rows, "practice", "v1").sort((a,b) => Number(a.q) - Number(b.q));

    const practiceTimeline = [
      videoTrial(PRACTICE_VIDEO, { practice: true }),
      prefSlider({ practice: true }),
      simultaneitySlider({ practice: true })
    ];

    if (practiceQs.length === 0) {
      practiceTimeline.push(
        screenTrial(`<div class="center"><p><em>No practice questions found (scene "practice", version "v1").</em></p></div>`, "Continue")
      );
    } else {
      practiceQs.forEach(q => {
        practiceTimeline.push( questionTrial(q, PRACTICE_SIDE, { practice: true }) );
      });
    }

      const practiceTrials = [
    { scene: "practice1", direction: "LtoR", moa: "demo", stimulus: "videos/practice1_LtoR_demo.mp4" }
  ];

    const practiceCompleteScreen = screenTrial(`
      <div class="center">
        <h3>Practice complete!</h3>
        <p>The main experiment will now begin.</p>
      </div>`, "Start main task");

/* ================================ Consent ================================= */
let CONSENT_GIVEN = false; // will still record consent
const CONSENT_HTML = `
  <div style="max-width:900px;margin:0 auto;text-align:left;font-size:16px;line-height:1.5">
    <h2 class="center">University at Albany, SUNY</h2>
    <h3 class="center">Informed Consent Information for Research Participation</h3>

    <p><strong>Study Title:</strong> Preferences and Memory for Short Animated Clips (Study 2)<br>
       <strong>Principal Investigator:</strong> Sijia (Estelle) Song, M.A., Department of Psychology, University at Albany<br>
       <strong>Faculty Advisor:</strong> Dr. Ronald Friedman, Professor of Psychology, University at Albany<br>
       <strong>Study Sponsor:</strong> This study is not externally sponsored.</p>

    <h4>Why are you doing this study?</h4>
    <p>You are being asked to participate in a research study about people’s preferences for and memory of short animated clips.
    The purpose of this study is to better understand how people respond to audiovisual information, including how much they enjoy short animated clips and how well they remember details from them.</p>

    <h4>Why am I eligible to participate in this study?</h4>
    <p>You must be at least 18 years old and have normal or corrected-to-normal hearing. Individuals who have previously participated or enrolled in a related study titled 
    "Preferences and Memory for Short Animated Clips (Study 1)" will also be automatically excluded from enrolling in the proposed study via Sona.</p>

    <h4>What will I do if I choose to be in this study?</h4>
    <p>If you choose to participate, you will:</p>
    <ol>
      <li>Watch a set of short animated videos.</li>
      <li>After each video, answer three questions:
        <ul>
          <li>How much you liked the video.</li>
          <li>Whether the picture and sound seemed to start together.</li>
          <li>Four short memory questions about the video.</li>
        </ul>
      </li>
      <li>At the end, you will answer a few quick demographic questions about yourself (e.g., age, gender, hearing status).</li>
    </ol>
    <p>Participation will take place entirely online in a single session and will take approximately 30 minutes.</p>

    <h4>Are there any costs I should be aware of?</h4>
    <p>There are no costs associated with participating in this study other than your time and internet usage.</p>

    <h4>What are the possible risks or discomforts?</h4>
    <p>We do not anticipate more than minimal risk from your participation.</p>
    <ul>
      <li>You may feel some discomfort if you find certain questions uninteresting or repetitive.</li>
      <li>As with all online research, there is a small risk of breach of confidentiality. We will take steps to minimize this risk, as described below.</li>
    </ul>
    <p>This study will not involve any audio or video recording of you.</p>

    <h4>What are the possible benefits for me or others?</h4>
    <p>You may not directly benefit from participating in this study. However, the knowledge gained may help researchers better understand how people experience and remember audiovisual media.</p>

    <h4>Will I receive compensation for my participation?</h4>
    <p>Yes. Students who participate will receive <strong>0.5 research credit</strong> toward the APSY 101 (Introductory Psychology) course requirement.</p>

    <h4>How will you protect the information you collect about me, and how will that information be shared?</h4>
    <p>Your participation is confidential. No identifying information (such as your name or email address) will be collected.</p>
    <p>All data will be stored securely in University at Albany OneDrive, accessible only to the research team. Data will be retained for a minimum of three (3) years and a maximum of five (5) years, after which it will be permanently destroyed.</p>
    <p>Study results will be reported in aggregate (group-level) form in academic publications and presentations. Individual responses will not be linked to your identity.</p>

    <h4>Will my data be used in future research?</h4>
    <p>After removal of identifiers, your data may be used in future research studies or shared with other investigators without additional consent from you.</p>

    <h4>What are my rights as a research participant?</h4>
    <p>Your participation in this study is voluntary. You may skip any question you do not wish to answer, and you may withdraw at any time without penalty or loss of benefits. If you choose to withdraw, you may also request that your data not be used.</p>
    <p>If you are a University at Albany student or employee, choosing not to participate will not affect your grades, class standing, employment, or your relationship with the University.</p>

    <h4>Who can I contact if I have questions or concerns?</h4>
    <p><strong>For questions about this study:</strong><br>
    - Sijia (Estelle) Song – <a href="mailto:ssong@albany.edu">ssong@albany.edu</a><br>
    - Dr. Ronald Friedman (Faculty Advisor) – <a href="mailto:rfriedman@albany.edu">rfriedman@albany.edu</a></p>

    <p><strong>For questions about your rights as a research participant:</strong><br>
    Institutional Review Board<br>
    Office of Regulatory and Research Compliance<br>
    University at Albany<br>
    1400 Washington Ave, Biology 227<br>
    Albany, NY 12222<br>
    Phone: 1-866-857-5459<br>
    Email: <a href="mailto:rco@albany.edu">rco@albany.edu</a></p>

    <hr>
    <p><em>Consent Statement:</em> I have read (or been informed of) the information above. By clicking “I Agree” below, I consent to participate in this study.</p>
  </div>
`;

  const consentTrial = {
    type: jsPsychHtmlButtonResponse,
    stimulus: CONSENT_HTML,
    choices: ["Yes, I consent", "No, I do not consent"],
    on_finish: (data) => {
      data.phase = "consent";
      data.consent_choice = data.response === 0 ? "yes" : "no";
      CONSENT_GIVEN = (data.response === 0);
    }
  };
    /* ---------- Intro screens ---------- */
    const introScreens = [
    screenTrial(`
      <h2 class="center">Welcome to the study!</h2>
      <p style="text-align:left;">
        In this study, you will watch 18 short animated videos showing objects moving across the screen. 
        The sound will also move between your left and right headphones as the object moves.
      </p>
      <p style="text-align:left;">
        To clearly hear the sound moving from side to side, 
        <strong>please make sure you are wearing headphones in a quiet environment before continuing.</strong>
      </p>
      <p style="text-align:left;">
        Please note that you may need to scroll down to view the entire page of instructions or questions.
      </p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">What you'll do after each video</h3>
      <ol>
        <li><strong>Preference rating</strong> – “How much did you like the clip you just watched?”</li>
        <li><strong>Timing judgment</strong> – “To what extent did the visual and auditory motion begin at the same time?”<br>
          <small>This means: did the movement you <em>saw</em> and the movement you <em>heard</em> seem to start together, or did one begin slightly earlier?</small>
        </li>
        <li><strong>Memory test</strong> – You will answer four memory questions about the details of the video you just watched. You will be choosing from four options.</li>
      </ol>
      <p>After all 18 trials, you’ll answer a few brief demographic questions.</p>
    `, "Next"),
    screenTrial(`
      <h3 class="center">Using the sliders</h3>
      <p>For the preference and timing ratings, you will use a slider from <strong>0 to 4</strong>.</p>
      <ul>
        <li>Move the slider to the number that best matches your judgment.</li>
        <li>If you want to select <strong>2 (Neutral)</strong>, click directly on the scale at 2.</li>
      </ul>
      <p>Let's start with a practice trial to learn the task.</p>
    `, "Begin practice")
  ];

    /* ---------- Main trials (fully random per participant) ---------- */
    // For each scene, randomly permute MOAs across versions; direction is sampled independently per trial.
    const trials = [];
    for (const scene of SCENES) {
      const moasPerm = jsPsych.randomization.shuffle(MOAS.slice()); // random pairing per scene
      for (let i = 0; i < VERSIONS.length; i++) {
        const v   = VERSIONS[i];
        const moa = moasPerm[i];
        const dir = jsPsych.randomization.sampleWithoutReplacement(["LtoR","RtoL"], 1)[0];
        const stim = filename(scene, v, dir, moa);
        trials.push({ scene, version: v, dir, moa, stimulus: stim });
      }
    }

    // Randomize overall presentation order (18 trials)
    const shuffled = jsPsych.randomization.shuffle(trials);

    const mainTimeline = [
      screenTrial(`
        <div class="center">
          <h2>Welcome</h2>
          <p>You will watch 18 clips. After each clip, please answer all questions.</p>
        </div>`, "Begin")
    ];

    for (const t of shuffled) {
      const side = (t.dir === "LtoR") ? "left" : "right";
      mainTimeline.push( videoTrial(t.stimulus, t) );
      mainTimeline.push( prefSlider(t) );
      mainTimeline.push( simultaneitySlider(t) );

      const allQs = questionsFor(rows, t.scene, t.version);
      if (allQs.length === 0) {
        mainTimeline.push(
          screenTrial(`<div class="center"><p><em>No questions found for ${t.scene} ${t.version}.</em></p></div>`, "Continue")
        );
      } else {
        jsPsych.randomization.shuffle(allQs).forEach(q => {
          mainTimeline.push( questionTrial(q, side, t) );
        });
      }
    }

    mainTimeline.push(
      screenTrial('<div class="center"><p>Thanks! You’re all set.</p></div>', "Finish")
    );

    /* ---------- Final questions & Debrief ---------- */
    const q_age = oneTextQuestion({ name: "age", prompt: "1) Please enter your age.", placeholder: "e.g., 26; 52" });
    const q_gender = oneTextQuestion({ name: "gender", prompt: "2) Please enter your gender.", placeholder: "e.g., woman / man / nonbinary / prefer to self-describe" });
    const q_race = oneTextQuestion({ name: "race_ethnicity", prompt: "3) Please enter your race/ethnicity.", placeholder: "e.g., Asian; White; Black; Hispanic/Latino; Multiracial; …" });
    const q_hearing = oneTextQuestion({ name: "hearing", prompt: "4) Do you have normal hearing?", placeholder: "Yes / No / Unsure" });

const final_debrief = {
  type: jsPsychHtmlButtonResponse,
  stimulus: `
    <div style="max-width:820px;margin:0 auto;line-height:1.5;text-align:left;">
      <h2 class="center">Thank you for participating in this study!</h2>

      <p><strong>What was this study about?</strong><br>
      We’re studying how people remember short videos and how much they like them—especially when what you see and what you hear don’t line up perfectly. 
      In everyday life, sights and sounds usually start together (for example, you see a car move and hear it at the same time). 
      In our study, we sometimes made the sound’s movement start a little after the picture’s movement. 
      This timing gap is called motion onset asynchrony (MOA).</p>

      <p><strong>What did we test?</strong><br>
      We used three setups: no delay, a small delay, and a larger delay. 
      Our main idea is that a moderate delay might be “just right”—interesting enough to grab attention and help memory and liking, 
      but not so off that it feels distracting. We’ll also test whether liking helps explain memory—in other words, 
      whether clips you like more are also easier to remember when timing is a little off.</p>

      <p><strong>Why does this matter?</strong><br>
      Extended reality (XR) is used in training, education, games, and entertainment. Designers want experiences that people enjoy and also remember. 
      Those goals don’t always match: very immersive experiences can feel amazing yet sometimes make it harder to remember details, 
      while simpler setups can aid memory but feel less engaging. Our results can help find a better balance.</p>

      <p>If you would like to discuss the study further or are curious about this research, 
      please feel free to contact the researcher, <a href="mailto:ssong@albany.edu">Estelle Song</a>, 
      or the faculty advisor, <a href="mailto:rfriedman@albany.edu">Dr. Ronald Friedman</a>. 
      You may also contact either researcher if you would like your data withdrawn from the study. 
      If you choose to do so, you will still receive full credit for participation and will not be penalized in any way.</p>

      <p>If you experienced any discomfort during this study, or wish to discuss any other concerns, 
      you may contact the University Counseling Center at (518) 442-5800.</p>

      <p>Because this research is potentially important, we kindly ask that you please do not discuss the study with others before they participate. 
      Prior knowledge could affect their natural responses.</p>

      <p class="center"><strong>Thank you very much for your assistance with this project!</strong></p>
    </div>`,
  choices: ["Finish"]
};

const credit_section = {
  type: jsPsychHtmlButtonResponse,
  stimulus: `
    <div style="max-width:820px;margin:0 auto;line-height:1.5;text-align:left;">
      <h2 class="center">Research Credit Instructions</h2>
      <p>
        At the conclusion of this study, a <strong>unique completion code</strong> will be displayed on your screen. 
        Please record this code carefully and email it to 
        <a href="mailto:friedmanlab11@gmail.com">friedmanlab11@gmail.com</a> 
        to receive research credit.
      </p>
      <p><em>For confidentiality:</em> please include <strong>only</strong> the completion code in your email; 
      do not include your name, student ID, or any other personal information.</p>
    </div>`,
  choices: ["Finish"]
};
    
    /* ---------- Run ---------- */
    jsPsych.run([
      consentTrial,
      ...introScreens,
      ...practiceTimeline,
      practiceCompleteScreen,
      ...mainTimeline,
      q_age, q_gender, q_race, q_hearing,
      final_debrief,
      credit_section
    ]);
  })();
</script>
</html>


